{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all_models.ipynb \n",
    "\n",
    "Here we will run our data through all models to see which one performs best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Playercount  Initialprice\n",
      "328 2020-02-29        10612          9.99\n",
      "329 2020-03-01        10648          9.99\n",
      "330 2020-03-02         9096          9.99\n",
      "331 2020-03-03         8934          9.99\n",
      "332 2020-03-04         8837          9.99\n",
      "..         ...          ...           ...\n",
      "488 2020-08-08        10939          9.99\n",
      "489 2020-08-09        11414          9.99\n",
      "490 2020-08-10        10516          9.99\n",
      "491 2020-08-11        10571          9.99\n",
      "492 2020-08-12        10287          9.99\n",
      "\n",
      "[165 rows x 3 columns]\n",
      "328    0\n",
      "329    0\n",
      "330    0\n",
      "331    0\n",
      "332    0\n",
      "      ..\n",
      "488    0\n",
      "489    0\n",
      "490    0\n",
      "491    0\n",
      "492    0\n",
      "Name: Discount, Length: 165, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris, load_wine, load_digits, load_breast_cancer, load_diabetes\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# placeholder for when we actually have data we want to use\n",
    "sample_df = pd.read_csv('data/CombinedPricePlayerCountHistory/10.csv',encoding='utf-8')\n",
    "\n",
    "#read in csv, convert date column to datetime object\n",
    "sample_df['Date'] = pd.to_datetime(sample_df['Date'])\n",
    "\n",
    "#2/3 samples train/test split\n",
    "samples = len(sample_df)\n",
    "split = math.floor(samples * (2/3))\n",
    "\n",
    "#split at date 2/3 of the way through entry by using \"split\" to index into the df, get the date, and use that\n",
    "split_date = sample_df.iloc[split]['Date']\n",
    "split_date = pd.to_datetime(split_date)\n",
    "train_data = sample_df[sample_df['Date'] < split_date]\n",
    "test_data = sample_df[sample_df['Date'] >= split_date]\n",
    "\n",
    "#Considering 'Finalprice' spoils whether or not there is a discount/it's amount so we omit that feature\n",
    "#Set up training data\n",
    "X_train = train_data[['Date', 'Playercount', 'Initialprice']]\n",
    "y_train = train_data['Discount']\n",
    "\n",
    "#Set up testing data\n",
    "X_test = test_data[['Date', 'Playercount', 'Initialprice']]\n",
    "y_test = test_data['Discount']\n",
    "\n",
    "print(X_test)\n",
    "print(y_test)\n",
    "\n",
    "#convert dates into something more compatible with our model (dates are not ML friendly)\n",
    "X_train['DayOfWeek'] = X_train['Date'].dt.dayofweek\n",
    "X_train['Month'] = X_train['Date'].dt.month\n",
    "X_train['Year'] = X_train['Date'].dt.year\n",
    "X_test['DayOfWeek'] = X_test['Date'].dt.dayofweek\n",
    "X_test['Month'] = X_test['Date'].dt.month\n",
    "X_test['Year'] = X_test['Date'].dt.year\n",
    "\n",
    "#drop the old date\n",
    "X_train = X_train.drop(['Date'], axis=1)\n",
    "X_test = X_test.drop(['Date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Nearest Neighbors\n",
      "Training: 0.9115853658536586\n",
      "Testing: 0.9151515151515152\n",
      "\n",
      "\n",
      "Name: Linear SVM\n",
      "Training: 0.9024390243902439\n",
      "Testing: 0.30303030303030304\n",
      "\n",
      "\n",
      "Name: RBF SVM\n",
      "Training: 1.0\n",
      "Testing: 0.9151515151515152\n",
      "\n",
      "\n",
      "Name: Decision Tree\n",
      "Training: 0.9451219512195121\n",
      "Testing: 0.5636363636363636\n",
      "\n",
      "\n",
      "Name: Random Forest\n",
      "Training: 0.9298780487804879\n",
      "Testing: 0.9151515151515152\n",
      "\n",
      "\n",
      "Name: Neural Net\n",
      "Training: 0.8932926829268293\n",
      "Testing: 0.9151515151515152\n",
      "\n",
      "\n",
      "Name: AdaBoost\n",
      "Training: 0.9451219512195121\n",
      "Testing: 0.6545454545454545\n",
      "\n",
      "\n",
      "Name: Naive Bayes\n",
      "Training: 0.9115853658536586\n",
      "Testing: 0.9151515151515152\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "]\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    cn = names[i]\n",
    "    clf = classifiers[i]\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, y_predict)\n",
    "\n",
    "    y_predict = clf.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_predict)\n",
    "\n",
    "    print(\"Name:\", cn)\n",
    "    print(\"Training:\", train_acc)\n",
    "    print(\"Testing:\", test_acc)\n",
    "    print(\"\\n\")   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs425-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
