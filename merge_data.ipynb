{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge_data.ipynb\n",
    "\n",
    "This file is responsible for taking all of the separate game csvs and putting them into one so we can have one trained model\n",
    "\n",
    "After thinking on this some more it actually might make more sense to have a separate model for each game ... Still thinking this through though. Might depend on how computationally expensive it is to quickly train a model with one game's data and then make a prediction. One model could be better though if the game we are predicting has limited data and training one model off of only that data may not be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Game_ID        Date  Playercount  Initialprice  Finalprice  Discount\n",
      "0       614570  2019-04-07          103         29.99       29.99         0\n",
      "1       614570  2019-04-08           71         29.99       29.99         0\n",
      "2       614570  2019-04-09           67         29.99       29.99         0\n",
      "3       614570  2019-04-10           58         29.99       29.99         0\n",
      "4       614570  2019-04-11           55         29.99       29.99         0\n",
      "...        ...         ...          ...           ...         ...       ...\n",
      "597477  228280  2020-08-08          622         19.99       19.99         0\n",
      "597478  228280  2020-08-09          688         19.99       19.99         0\n",
      "597479  228280  2020-08-10          558         19.99       19.99         0\n",
      "597480  228280  2020-08-11          529         19.99       19.99         0\n",
      "597481  228280  2020-08-12          520         19.99       19.99         0\n",
      "\n",
      "[597482 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "folder = \"data/CombinedPricePlayerCountHistory\"\n",
    "game_dfs = []\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    if filename == \"readme.md\":\n",
    "        continue\n",
    "\n",
    "    # Construct filenames\n",
    "    fullpath = os.path.join(folder, filename)\n",
    "    appId, garbage_collector = os.path.splitext(filename)\n",
    "\n",
    "    # Create data frame for each csv\n",
    "    df = pd.read_csv(fullpath)\n",
    "    df['Game_ID'] = appId\n",
    "    # Put Game_ID first for visual pleasure\n",
    "    cols = ['Game_ID'] + [col for col in df if col != 'Game_ID']\n",
    "    df = df[cols]\n",
    "    game_dfs.append(df)\n",
    "\n",
    "# Combine them into one csv we can use to train\n",
    "combined_df = pd.concat(game_dfs, ignore_index=True)\n",
    "\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run this data frame through the decision tree classifier to make sure it is still able to make predictions off of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'class_names' parameter of plot_tree must be an instance of 'list' or None. Got True instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/git/cs425/cs425-env/cs425-final/merge_data.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/git/cs425/cs425-env/cs425-final/merge_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/git/cs425/cs425-env/cs425-final/merge_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m8\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/git/cs425/cs425-env/cs425-final/merge_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m plot_tree(model, filled\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, feature_names\u001b[39m=\u001b[39;49mX_train\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mto_list(), class_names\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, rounded\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/git/cs425/cs425-env/cs425-final/merge_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/git/cs425/cs425-env/cs425-final/merge_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m#make predictions on the test set\u001b[39;00m\n",
      "File \u001b[0;32m/git/cs425/cs425-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:201\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m to_ignore \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    199\u001b[0m params \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m to_ignore}\n\u001b[0;32m--> 201\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    202\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39;49mfunc\u001b[39m.\u001b[39;49m\u001b[39m__qualname__\u001b[39;49m\n\u001b[1;32m    203\u001b[0m )\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n",
      "File \u001b[0;32m/git/cs425/cs425-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'class_names' parameter of plot_tree must be an instance of 'list' or None. Got True instead."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read in csv, convert date column to datetime object\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'])\n",
    "\n",
    "#2/3 samples train/test split\n",
    "samples = len(combined_df)\n",
    "split = math.floor(samples * (2/3))\n",
    "\n",
    "#split at date 2/3 of the way through entry by using \"split\" to index into the df, get the date, and use that\n",
    "split_date = combined_df.iloc[split]['Date']\n",
    "split_date = pd.to_datetime(split_date)\n",
    "train_data = combined_df[combined_df['Date'] < split_date]\n",
    "test_data = combined_df[combined_df['Date'] >= split_date]\n",
    "\n",
    "#Considering 'Finalprice' spoils whether or not there is a discount/it's amount so we omit that feature\n",
    "#Set up training data\n",
    "#X_train = train_data[['Date', 'Playercount', 'Initialprice','Finalprice']]\n",
    "X_train = train_data[['Date', 'Playercount', 'Initialprice']]\n",
    "y_train = train_data['Discount']\n",
    "\n",
    "#Set up testing data\n",
    "#X_test = test_data[['Date', 'Playercount', 'Initialprice','Finalprice']]\n",
    "X_test = test_data[['Date', 'Playercount', 'Initialprice']]\n",
    "y_test = test_data['Discount']\n",
    "\n",
    "#convert dates into something more compatible with our model (dates are not ML friendly)\n",
    "X_train['DayOfWeek'] = X_train['Date'].dt.dayofweek\n",
    "X_train['Month'] = X_train['Date'].dt.month\n",
    "X_train['Year'] = X_train['Date'].dt.year\n",
    "X_test['DayOfWeek'] = X_test['Date'].dt.dayofweek\n",
    "X_test['Month'] = X_test['Date'].dt.month\n",
    "X_test['Year'] = X_test['Date'].dt.year\n",
    "\n",
    "#drop the old date\n",
    "X_train = X_train.drop(['Date'], axis=1)\n",
    "X_test = X_test.drop(['Date'], axis=1)\n",
    "\n",
    "#fit classifier to training data\n",
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(model, filled=True, feature_names=X_train.columns.to_list(), rounded=True)\n",
    "plt.show()\n",
    "\n",
    "#make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#evaluate/print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Accuracy:',accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs425-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
