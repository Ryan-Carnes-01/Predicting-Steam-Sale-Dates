{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge_data.ipynb\n",
    "\n",
    "This file is responsible for taking all of the separate game csvs and putting them into one so we can have one trained model\n",
    "\n",
    "After thinking on this some more it actually might make more sense to have a separate model for each game ... Still thinking this through though. Might depend on how computationally expensive it is to quickly train a model with one game's data and then make a prediction. One model could be better though if the game we are predicting has limited data and training one model off of only that data may not be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Game_ID        Date  Playercount  Initialprice  Finalprice  Discount\n",
      "0       614570  2019-04-07          103         29.99       29.99         0\n",
      "1       614570  2019-04-08           71         29.99       29.99         0\n",
      "2       614570  2019-04-09           67         29.99       29.99         0\n",
      "3       614570  2019-04-10           58         29.99       29.99         0\n",
      "4       614570  2019-04-11           55         29.99       29.99         0\n",
      "...        ...         ...          ...           ...         ...       ...\n",
      "597477  228280  2020-08-08          622         19.99       19.99         0\n",
      "597478  228280  2020-08-09          688         19.99       19.99         0\n",
      "597479  228280  2020-08-10          558         19.99       19.99         0\n",
      "597480  228280  2020-08-11          529         19.99       19.99         0\n",
      "597481  228280  2020-08-12          520         19.99       19.99         0\n",
      "\n",
      "[597482 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "folder = \"data/CombinedPricePlayerCountHistory\"\n",
    "game_dfs = []\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    if filename == \"readme.md\":\n",
    "        continue\n",
    "\n",
    "    # Construct filenames\n",
    "    fullpath = os.path.join(folder, filename)\n",
    "    appId, garbage_collector = os.path.splitext(filename)\n",
    "\n",
    "    # Create data frame for each csv\n",
    "    df = pd.read_csv(fullpath)\n",
    "    df['Game_ID'] = appId\n",
    "    # Put Game_ID first for visual pleasure\n",
    "    cols = ['Game_ID'] + [col for col in df if col != 'Game_ID']\n",
    "    df = df[cols]\n",
    "    game_dfs.append(df)\n",
    "\n",
    "# Combine them into one csv we can use to train\n",
    "combined_df = pd.concat(game_dfs, ignore_index=True)\n",
    "\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run this data frame through the decision tree classifier to make sure it is still able to make predictions off of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7743872298814756\n"
     ]
    }
   ],
   "source": [
    "#read in csv, convert date column to datetime object\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'])\n",
    "\n",
    "#2/3 samples train/test split\n",
    "samples = len(combined_df)\n",
    "split = math.floor(samples * (2/3))\n",
    "\n",
    "#split at date 2/3 of the way through entry by using \"split\" to index into the df, get the date, and use that\n",
    "split_date = combined_df.iloc[split]['Date']\n",
    "split_date = pd.to_datetime(split_date)\n",
    "train_data = combined_df[combined_df['Date'] < split_date]\n",
    "test_data = combined_df[combined_df['Date'] >= split_date]\n",
    "\n",
    "#Considering 'Finalprice' spoils whether or not there is a discount/it's amount so we omit that feature\n",
    "#Set up training data\n",
    "#X_train = train_data[['Date', 'Playercount', 'Initialprice','Finalprice']]\n",
    "X_train = train_data[['Date', 'Playercount', 'Initialprice']]\n",
    "y_train = train_data['Discount']\n",
    "\n",
    "#Set up testing data\n",
    "#X_test = test_data[['Date', 'Playercount', 'Initialprice','Finalprice']]\n",
    "X_test = test_data[['Date', 'Playercount', 'Initialprice']]\n",
    "y_test = test_data['Discount']\n",
    "\n",
    "#convert dates into something more compatible with our model (dates are not ML friendly)\n",
    "X_train['DayOfWeek'] = X_train['Date'].dt.dayofweek\n",
    "X_train['Month'] = X_train['Date'].dt.month\n",
    "X_train['Year'] = X_train['Date'].dt.year\n",
    "X_test['DayOfWeek'] = X_test['Date'].dt.dayofweek\n",
    "X_test['Month'] = X_test['Date'].dt.month\n",
    "X_test['Year'] = X_test['Date'].dt.year\n",
    "\n",
    "#drop the old date\n",
    "X_train = X_train.drop(['Date'], axis=1)\n",
    "X_test = X_test.drop(['Date'], axis=1)\n",
    "\n",
    "#fit classifier to training data\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#evaluate/print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Accuracy:',accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs425-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
